{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Game Theory Foundations\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/blockchain-tokens-and-incentives/blob/main/notebooks/tutorial_02_game_theory_foundations.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "> *\"A guild member does not cooperate because he is virtuous. He cooperates because, in a repeated game with memory, cooperation is the strategy that maximizes cumulative payoff.\"*\n",
    ">\n",
    "> — Brenn Auster, *On the Alignment of Interest and Obligation* (Year 875)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Observation to Theory\n",
    "\n",
    "Tutorial 01 showed the guild's enforcement failure: defection is rational in one-shot games, inspectors can be bribed, and the enforcement paradox means more rules can make things worse.\n",
    "\n",
    "Auster needed a formal framework. Game theory — the mathematics of strategic interaction — provides exactly that. This tutorial builds the theoretical machinery that makes mechanism design (Tutorial 03) possible.\n",
    "\n",
    "We will analyze the `game_theory_outcomes.csv` dataset: 30 matches of the iterated Prisoner's Dilemma, each running 10 rounds, with 8 different strategies competing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "In this tutorial, you will:\n",
    "\n",
    "1. **Formalize the Prisoner's Dilemma** — payoff matrices, strategy spaces, solution concepts\n",
    "2. **Find Nash equilibria** — strategy profiles where no player can improve by switching\n",
    "3. **Implement and analyze 8 strategies** — from always-defect to tit-for-tat to pavlov\n",
    "4. **Run a strategy tournament** — which strategy wins in repeated games?\n",
    "5. **Understand how repetition transforms the game** — the Folk Theorem and the shadow of the future\n",
    "\n",
    "**Technical Concepts:**\n",
    "- Nash equilibrium and dominant strategies\n",
    "- Iterated Prisoner's Dilemma and Axelrod's tournament\n",
    "- Tit-for-tat, grim trigger, pavlov\n",
    "- The Folk Theorem: why cooperation can be sustained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/densworld-datasets/main/data/\"\n",
    "\n",
    "game_theory = pd.read_csv(BASE_URL + \"game_theory_outcomes.csv\")\n",
    "\n",
    "print(f\"Game theory outcomes: {len(game_theory)} rounds\")\n",
    "print(f\"Matches: {game_theory['match_id'].nunique()}\")\n",
    "print(f\"Rounds per match: {game_theory.groupby('match_id')['round'].max().unique()}\")\n",
    "print(f\"Strategies: {sorted(set(game_theory['strategy_a']) | set(game_theory['strategy_b']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalizing the Game\n",
    "\n",
    "A **game** in game theory has three components:\n",
    "1. **Players** — the decision makers (two guild traders)\n",
    "2. **Strategies** — the available actions (cooperate or defect)\n",
    "3. **Payoffs** — the outcomes for each combination of actions\n",
    "\n",
    "The Prisoner's Dilemma uses the payoff ordering **T > R > P > S** and **2R > T + S**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formal payoff matrix\n",
    "T, R, P, S = 5, 3, 1, 0  # Temptation, Reward, Punishment, Sucker\n",
    "\n",
    "PAYOFF_MATRIX = {\n",
    "    ('cooperate', 'cooperate'): (R, R),\n",
    "    ('cooperate', 'defect'):    (S, T),\n",
    "    ('defect', 'cooperate'):    (T, S),\n",
    "    ('defect', 'defect'):       (P, P),\n",
    "}\n",
    "\n",
    "print(\"Prisoner's Dilemma Payoff Matrix:\")\n",
    "print(f\"\\n  T={T} (Temptation to defect)\")\n",
    "print(f\"  R={R} (Reward for mutual cooperation)\")\n",
    "print(f\"  P={P} (Punishment for mutual defection)\")\n",
    "print(f\"  S={S} (Sucker's payoff)\")\n",
    "print(f\"\\n  Conditions: T > R > P > S: {T} > {R} > {P} > {S} ✓\")\n",
    "print(f\"  Conditions: 2R > T + S: {2*R} > {T+S} ✓ (cooperation is efficient)\")\n",
    "\n",
    "# Display as a proper matrix\n",
    "print(f\"\\n{'':20s} {'B: Cooperate':>15s} {'B: Defect':>15s}\")\n",
    "print(f\"{'A: Cooperate':20s} {'(R,R)=(3,3)':>15s} {'(S,T)=(0,5)':>15s}\")\n",
    "print(f\"{'A: Defect':20s} {'(T,S)=(5,0)':>15s} {'(P,P)=(1,1)':>15s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nash Equilibrium\n",
    "\n",
    "A **Nash equilibrium** is a strategy profile where no player can improve their payoff by unilaterally changing their strategy. In the one-shot Prisoner's Dilemma, (Defect, Defect) is the unique Nash equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nash_equilibria(payoff_matrix):\n",
    "    \"\"\"Find all pure-strategy Nash equilibria in a 2-player game.\"\"\"\n",
    "    actions = ['cooperate', 'defect']\n",
    "    equilibria = []\n",
    "    \n",
    "    for a1, a2 in product(actions, repeat=2):\n",
    "        pay_a, pay_b = payoff_matrix[(a1, a2)]\n",
    "        \n",
    "        # Check: can A improve by switching?\n",
    "        a_alt = 'defect' if a1 == 'cooperate' else 'cooperate'\n",
    "        alt_pay_a, _ = payoff_matrix[(a_alt, a2)]\n",
    "        a_can_improve = alt_pay_a > pay_a\n",
    "        \n",
    "        # Check: can B improve by switching?\n",
    "        b_alt = 'defect' if a2 == 'cooperate' else 'cooperate'\n",
    "        _, alt_pay_b = payoff_matrix[(a1, b_alt)]\n",
    "        b_can_improve = alt_pay_b > pay_b\n",
    "        \n",
    "        is_nash = not a_can_improve and not b_can_improve\n",
    "        \n",
    "        print(f\"  ({a1:9s}, {a2:9s}) → payoffs ({pay_a}, {pay_b})\")\n",
    "        print(f\"    A switch to {a_alt}: payoff {alt_pay_a} {'> ' + str(pay_a) + ' (improves)' if a_can_improve else '<= ' + str(pay_a) + ' (no improvement)'}\")\n",
    "        print(f\"    B switch to {b_alt}: payoff {alt_pay_b} {'> ' + str(pay_b) + ' (improves)' if b_can_improve else '<= ' + str(pay_b) + ' (no improvement)'}\")\n",
    "        print(f\"    Nash equilibrium: {'YES ✓' if is_nash else 'no'}\")\n",
    "        print()\n",
    "        \n",
    "        if is_nash:\n",
    "            equilibria.append((a1, a2, pay_a, pay_b))\n",
    "    \n",
    "    return equilibria\n",
    "\n",
    "print(\"Finding Nash equilibria in the Prisoner's Dilemma:\\n\")\n",
    "equilibria = find_nash_equilibria(PAYOFF_MATRIX)\n",
    "print(f\"Nash equilibria: {[(e[0], e[1]) for e in equilibria]}\")\n",
    "print(f\"\\nThe only Nash equilibrium is (Defect, Defect) with payoffs (1, 1).\")\n",
    "print(f\"But (Cooperate, Cooperate) gives (3, 3). The dilemma: the equilibrium is inefficient.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominant Strategies\n",
    "\n",
    "A **dominant strategy** is one that gives a better payoff than any alternative, regardless of what the opponent does. In the PD, defection is strictly dominant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dominance(payoff_matrix):\n",
    "    \"\"\"Check for strictly dominant strategies.\"\"\"\n",
    "    actions = ['cooperate', 'defect']\n",
    "    \n",
    "    for player_label, idx in [('Player A', 0), ('Player B', 1)]:\n",
    "        print(f\"{player_label}:\")\n",
    "        for my_action in actions:\n",
    "            payoffs = []\n",
    "            for opp_action in actions:\n",
    "                if idx == 0:\n",
    "                    pay = payoff_matrix[(my_action, opp_action)][idx]\n",
    "                else:\n",
    "                    pay = payoff_matrix[(opp_action, my_action)][idx]\n",
    "                payoffs.append((opp_action, pay))\n",
    "            print(f\"  {my_action:10s} → {payoffs}\")\n",
    "        \n",
    "        # Check if defect dominates cooperate\n",
    "        defect_payoffs = [payoff_matrix[('defect', a)][0] if idx == 0 \n",
    "                          else payoff_matrix[(a, 'defect')][1] for a in actions]\n",
    "        coop_payoffs = [payoff_matrix[('cooperate', a)][0] if idx == 0 \n",
    "                        else payoff_matrix[(a, 'cooperate')][1] for a in actions]\n",
    "        \n",
    "        dominates = all(d > c for d, c in zip(defect_payoffs, coop_payoffs))\n",
    "        print(f\"  Defect dominates cooperate: {dominates}\\n\")\n",
    "\n",
    "check_dominance(PAYOFF_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Eight Strategies\n",
    "\n",
    "The guild members use 8 different strategies. Let's implement each one and understand its logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def always_cooperate(my_history, opp_history, round_num):\n",
    "    return 'cooperate'\n",
    "\n",
    "def always_defect(my_history, opp_history, round_num):\n",
    "    return 'defect'\n",
    "\n",
    "def tit_for_tat(my_history, opp_history, round_num):\n",
    "    \"\"\"Cooperate first, then copy opponent's last move.\"\"\"\n",
    "    if round_num == 1:\n",
    "        return 'cooperate'\n",
    "    return opp_history[-1]\n",
    "\n",
    "def generous_tit_for_tat(my_history, opp_history, round_num):\n",
    "    \"\"\"Like tit-for-tat, but forgive 10% of defections.\"\"\"\n",
    "    if round_num == 1:\n",
    "        return 'cooperate'\n",
    "    if opp_history[-1] == 'defect':\n",
    "        return 'cooperate' if np.random.random() < 0.1 else 'defect'\n",
    "    return 'cooperate'\n",
    "\n",
    "def random_strategy(my_history, opp_history, round_num):\n",
    "    return np.random.choice(['cooperate', 'defect'])\n",
    "\n",
    "def grim_trigger(my_history, opp_history, round_num):\n",
    "    \"\"\"Cooperate until opponent defects once, then defect forever.\"\"\"\n",
    "    if 'defect' in opp_history:\n",
    "        return 'defect'\n",
    "    return 'cooperate'\n",
    "\n",
    "def pavlov(my_history, opp_history, round_num):\n",
    "    \"\"\"Repeat last action if it paid well; switch otherwise.\"\"\"\n",
    "    if round_num == 1:\n",
    "        return 'cooperate'\n",
    "    if my_history[-1] == opp_history[-1]:\n",
    "        return my_history[-1]\n",
    "    return 'defect' if my_history[-1] == 'cooperate' else 'cooperate'\n",
    "\n",
    "def suspicious_tit_for_tat(my_history, opp_history, round_num):\n",
    "    \"\"\"Like tit-for-tat but starts with defection.\"\"\"\n",
    "    if round_num == 1:\n",
    "        return 'defect'\n",
    "    return opp_history[-1]\n",
    "\n",
    "STRATEGIES = {\n",
    "    'always_cooperate': always_cooperate,\n",
    "    'always_defect': always_defect,\n",
    "    'tit_for_tat': tit_for_tat,\n",
    "    'generous_tit_for_tat': generous_tit_for_tat,\n",
    "    'random': random_strategy,\n",
    "    'grim_trigger': grim_trigger,\n",
    "    'pavlov': pavlov,\n",
    "    'suspicious_tit_for_tat': suspicious_tit_for_tat,\n",
    "}\n",
    "\n",
    "print(f\"Implemented {len(STRATEGIES)} strategies:\")\n",
    "for name, fn in STRATEGIES.items():\n",
    "    print(f\"  {name:30s} — {fn.__doc__ or 'No description'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Match\n",
    "\n",
    "Let's build a match simulator and watch two strategies play against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_match(strategy_a_fn, strategy_b_fn, rounds=10):\n",
    "    \"\"\"Play a match between two strategies. Returns round-by-round results.\"\"\"\n",
    "    history_a, history_b = [], []\n",
    "    results = []\n",
    "    \n",
    "    for r in range(1, rounds + 1):\n",
    "        action_a = strategy_a_fn(history_a, history_b, r)\n",
    "        action_b = strategy_b_fn(history_b, history_a, r)\n",
    "        payoff_a, payoff_b = PAYOFF_MATRIX[(action_a, action_b)]\n",
    "        \n",
    "        history_a.append(action_a)\n",
    "        history_b.append(action_b)\n",
    "        \n",
    "        results.append({\n",
    "            'round': r, 'action_a': action_a, 'action_b': action_b,\n",
    "            'payoff_a': payoff_a, 'payoff_b': payoff_b,\n",
    "            'cumulative_a': sum(rr['payoff_a'] for rr in results) + payoff_a,\n",
    "            'cumulative_b': sum(rr['payoff_b'] for rr in results) + payoff_b,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Classic matchup: tit_for_tat vs always_defect\n",
    "match = play_match(STRATEGIES['tit_for_tat'], STRATEGIES['always_defect'])\n",
    "\n",
    "print(\"Match: tit_for_tat (A) vs always_defect (B)\\n\")\n",
    "print(f\"{'Round':>5s} {'A Action':>12s} {'B Action':>12s} {'A Pay':>6s} {'B Pay':>6s} {'A Cum':>6s} {'B Cum':>6s}\")\n",
    "for _, row in match.iterrows():\n",
    "    print(f\"{int(row['round']):5d} {row['action_a']:>12s} {row['action_b']:>12s} \"\n",
    "          f\"{int(row['payoff_a']):6d} {int(row['payoff_b']):6d} \"\n",
    "          f\"{int(row['cumulative_a']):6d} {int(row['cumulative_b']):6d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize three key matchups\n",
    "matchups = [\n",
    "    ('tit_for_tat', 'tit_for_tat', 'TFT vs TFT (mutual cooperation)'),\n",
    "    ('tit_for_tat', 'always_defect', 'TFT vs Always Defect'),\n",
    "    ('always_defect', 'always_defect', 'Defect vs Defect (Nash equilibrium)'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for ax, (sa, sb, title) in zip(axes, matchups):\n",
    "    np.random.seed(42)\n",
    "    m = play_match(STRATEGIES[sa], STRATEGIES[sb])\n",
    "    ax.plot(m['round'], m['cumulative_a'], 'o-', label=sa, color='steelblue')\n",
    "    ax.plot(m['round'], m['cumulative_b'], 's--', label=sb, color='firebrick')\n",
    "    ax.set_xlabel('Round')\n",
    "    ax.set_ylabel('Cumulative Payoff')\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Dataset\n",
    "\n",
    "Our dataset contains 30 matches from the guild's game theory experiments. Let's analyze strategy performance across all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy performance from the dataset (final-round cumulative payoffs)\n",
    "final_rounds = game_theory[game_theory['round'] == 10].copy()\n",
    "\n",
    "# Collect all payoffs for each strategy (whether played as A or B)\n",
    "strategy_payoffs = {}\n",
    "for _, row in final_rounds.iterrows():\n",
    "    sa, sb = row['strategy_a'], row['strategy_b']\n",
    "    pa, pb = row['cumulative_payoff_a'], row['cumulative_payoff_b']\n",
    "    strategy_payoffs.setdefault(sa, []).append(pa)\n",
    "    strategy_payoffs.setdefault(sb, []).append(pb)\n",
    "\n",
    "# Compute stats\n",
    "perf = pd.DataFrame([\n",
    "    {'strategy': s, 'avg_payoff': np.mean(pays), 'std': np.std(pays),\n",
    "     'min': np.min(pays), 'max': np.max(pays), 'matches': len(pays)}\n",
    "    for s, pays in strategy_payoffs.items()\n",
    "]).sort_values('avg_payoff', ascending=False)\n",
    "\n",
    "print(\"Strategy Tournament Results (from dataset):\")\n",
    "print(f\"{'Strategy':30s} {'Avg':>6s} {'Std':>6s} {'Min':>5s} {'Max':>5s} {'N':>4s}\")\n",
    "for _, row in perf.iterrows():\n",
    "    print(f\"{row['strategy']:30s} {row['avg_payoff']:6.1f} {row['std']:6.1f} \"\n",
    "          f\"{int(row['min']):5d} {int(row['max']):5d} {int(row['matches']):4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize strategy rankings\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#2ecc71' if 'cooperate' in s or 'tit' in s or 'pavlov' in s or 'grim' in s \n",
    "          else '#e74c3c' if 'defect' in s else '#f39c12'\n",
    "          for s in perf['strategy']]\n",
    "plt.barh(perf['strategy'], perf['avg_payoff'], xerr=perf['std'],\n",
    "         color=colors, alpha=0.8, edgecolor='black', capsize=3)\n",
    "plt.xlabel('Average Cumulative Payoff (10 rounds)')\n",
    "plt.title('Strategy Tournament: Who Wins the Guild Game?')\n",
    "plt.axvline(x=10, color='gray', linestyle=':', alpha=0.5, label='Mutual defection baseline (10)')\n",
    "plt.axvline(x=30, color='gray', linestyle='--', alpha=0.5, label='Mutual cooperation optimum (30)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Green = cooperative strategies | Red = defective | Orange = mixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round-by-Round Dynamics\n",
    "\n",
    "The aggregate scores tell part of the story. The round-by-round dynamics reveal how strategies interact over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooperation rate over rounds\n",
    "round_coop = game_theory.groupby('round').agg(\n",
    "    coop_a=('action_a', lambda x: (x == 'cooperate').mean()),\n",
    "    coop_b=('action_b', lambda x: (x == 'cooperate').mean()),\n",
    ").reset_index()\n",
    "round_coop['avg_cooperation'] = (round_coop['coop_a'] + round_coop['coop_b']) / 2\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(round_coop['round'], round_coop['avg_cooperation'], 'o-',\n",
    "         color='steelblue', linewidth=2, markersize=8)\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Cooperation Rate')\n",
    "plt.title('Average Cooperation Rate Over Rounds (All 30 Matches)')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Round 1 cooperation: {round_coop.iloc[0]['avg_cooperation']:.2%}\")\n",
    "print(f\"Round 10 cooperation: {round_coop.iloc[-1]['avg_cooperation']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-strategy cooperation evolution\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "strategies_list = sorted(game_theory['strategy_a'].unique())\n",
    "\n",
    "for ax, strat in zip(axes.flat, strategies_list):\n",
    "    mask_a = game_theory['strategy_a'] == strat\n",
    "    mask_b = game_theory['strategy_b'] == strat\n",
    "    \n",
    "    coop_as_a = game_theory[mask_a].groupby('round')['action_a'].apply(\n",
    "        lambda x: (x == 'cooperate').mean())\n",
    "    coop_as_b = game_theory[mask_b].groupby('round')['action_b'].apply(\n",
    "        lambda x: (x == 'cooperate').mean())\n",
    "    \n",
    "    all_coop = pd.concat([coop_as_a, coop_as_b]).groupby(level=0).mean()\n",
    "    \n",
    "    ax.plot(all_coop.index, all_coop.values, 'o-', color='steelblue', markersize=4)\n",
    "    ax.set_title(strat.replace('_', ' '), fontsize=9)\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.set_xlabel('Round', fontsize=8)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Cooperation Rate by Strategy Over Rounds', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Round-Robin Tournament\n",
    "\n",
    "Let's run a complete round-robin where every strategy plays every other strategy (and itself) over 10 rounds. This follows Axelrod's famous tournament design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full round-robin tournament\n",
    "np.random.seed(875)  # Year of Auster's alignment paper\n",
    "\n",
    "tournament_results = {}\n",
    "matchup_details = []\n",
    "\n",
    "for sa_name, sa_fn in STRATEGIES.items():\n",
    "    total_payoff = 0\n",
    "    n_matches = 0\n",
    "    for sb_name, sb_fn in STRATEGIES.items():\n",
    "        match_df = play_match(sa_fn, sb_fn, rounds=10)\n",
    "        final_payoff_a = match_df.iloc[-1]['cumulative_a']\n",
    "        final_payoff_b = match_df.iloc[-1]['cumulative_b']\n",
    "        total_payoff += final_payoff_a\n",
    "        n_matches += 1\n",
    "        matchup_details.append({\n",
    "            'strategy_a': sa_name, 'strategy_b': sb_name,\n",
    "            'payoff_a': final_payoff_a, 'payoff_b': final_payoff_b\n",
    "        })\n",
    "    tournament_results[sa_name] = total_payoff / n_matches\n",
    "\n",
    "# Sort by performance\n",
    "sorted_results = sorted(tournament_results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Round-Robin Tournament Results:\")\n",
    "print(f\"{'Rank':>4s} {'Strategy':30s} {'Avg Payoff':>10s}\")\n",
    "for rank, (strategy, avg) in enumerate(sorted_results, 1):\n",
    "    marker = ' ← WINNER' if rank == 1 else ''\n",
    "    print(f\"{rank:4d} {strategy:30s} {avg:10.1f}{marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matchup heatmap\n",
    "matchup_df = pd.DataFrame(matchup_details)\n",
    "pivot = matchup_df.pivot(index='strategy_a', columns='strategy_b', values='payoff_a')\n",
    "\n",
    "# Sort by tournament ranking\n",
    "rank_order = [s for s, _ in sorted_results]\n",
    "pivot = pivot.reindex(index=rank_order, columns=rank_order)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(pivot.values, cmap='RdYlGn', aspect='auto')\n",
    "ax.set_xticks(range(len(rank_order)))\n",
    "ax.set_yticks(range(len(rank_order)))\n",
    "ax.set_xticklabels([s.replace('_', '\\n') for s in rank_order], fontsize=7, rotation=45, ha='right')\n",
    "ax.set_yticklabels([s.replace('_', ' ') for s in rank_order], fontsize=8)\n",
    "ax.set_xlabel('Opponent')\n",
    "ax.set_ylabel('Player')\n",
    "ax.set_title('Payoff Heatmap: Row Player vs Column Opponent')\n",
    "\n",
    "for i in range(len(rank_order)):\n",
    "    for j in range(len(rank_order)):\n",
    "        ax.text(j, i, f\"{pivot.values[i,j]:.0f}\", ha='center', va='center', fontsize=7)\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='Cumulative Payoff (10 rounds)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Folk Theorem: Why Cooperation Survives\n",
    "\n",
    "In a one-shot game, defection dominates. But the **Folk Theorem** proves that in infinitely repeated games (or games with unknown end), *any* outcome where both players earn at least their minimax payoff can be sustained as a Nash equilibrium — including mutual cooperation.\n",
    "\n",
    "The key parameter is the **discount factor** (δ): how much players value future payoffs relative to present ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Folk Theorem condition for cooperation via tit-for-tat:\n",
    "# Cooperation is sustained if discount factor δ ≥ (T - R) / (T - P)\n",
    "\n",
    "delta_threshold = (T - R) / (T - P)\n",
    "\n",
    "print(f\"Folk Theorem threshold for Prisoner's Dilemma cooperation:\")\n",
    "print(f\"  δ ≥ (T - R) / (T - P) = ({T} - {R}) / ({T} - {P}) = {delta_threshold:.2f}\")\n",
    "print(f\"\\nIf players value future payoffs at ≥ {delta_threshold:.0%} of present payoffs,\")\n",
    "print(f\"tit-for-tat sustains cooperation as a Nash equilibrium.\")\n",
    "\n",
    "# Visualize: cooperation viability by discount factor\n",
    "deltas = np.linspace(0, 1, 100)\n",
    "coop_payoff = np.where(deltas >= delta_threshold, R / (1 - deltas + 1e-10), P / (1 - deltas + 1e-10))\n",
    "defect_payoff = np.full_like(deltas, P / (1 - deltas[50] + 1e-10))  # Always defect baseline\n",
    "\n",
    "# Simpler: expected per-round payoff under cooperation vs defection\n",
    "coop_per_round = R  # 3 per round if both cooperate\n",
    "defect_per_round = P  # 1 per round if both defect\n",
    "tempt_first_round = T  # 5 for defecting against cooperator\n",
    "\n",
    "# Value of defecting against tit-for-tat: get T first round, then P forever\n",
    "defect_values = [tempt_first_round + defect_per_round * d / (1 - d + 1e-10) \n",
    "                 for d in deltas]\n",
    "# Value of cooperating with tit-for-tat: get R every round\n",
    "coop_values = [coop_per_round / (1 - d + 1e-10) for d in deltas]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(deltas, coop_values, '-', color='steelblue', linewidth=2, label='Cooperate (R every round)')\n",
    "plt.plot(deltas, defect_values, '--', color='firebrick', linewidth=2, label='Defect once then punished')\n",
    "plt.axvline(x=delta_threshold, color='black', linestyle=':', label=f'δ* = {delta_threshold:.2f}')\n",
    "plt.xlabel('Discount Factor (δ)')\n",
    "plt.ylabel('Total Discounted Payoff')\n",
    "plt.title('The Folk Theorem: When Cooperation Becomes Self-Enforcing')\n",
    "plt.legend()\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dens Interference\n",
    "\n",
    "Our dataset includes a `dens_interference` flag — a 5% chance that a player's intended action gets flipped. This models the instability near the Dens and has real implications: in a world with noise, forgiving strategies outperform strict ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dens interference analysis\n",
    "interference = game_theory[game_theory['dens_interference'] == True]\n",
    "no_interference = game_theory[game_theory['dens_interference'] == False]\n",
    "\n",
    "print(f\"Rounds with Dens interference: {len(interference)} ({len(interference)/len(game_theory):.1%})\")\n",
    "print(f\"Rounds without: {len(no_interference)}\")\n",
    "\n",
    "# Does interference affect cooperation rates?\n",
    "intf_coop = (interference['action_a'] == 'cooperate').mean()\n",
    "no_intf_coop = (no_interference['action_a'] == 'cooperate').mean()\n",
    "print(f\"\\nCooperation rate with interference: {intf_coop:.2%}\")\n",
    "print(f\"Cooperation rate without: {no_intf_coop:.2%}\")\n",
    "\n",
    "# This matters for strategy selection:\n",
    "# Grim trigger is CATASTROPHIC with noise (one accidental defect = permanent punishment)\n",
    "# Generous tit-for-tat is robust (forgives occasional defections)\n",
    "print(f\"\\nIn noisy environments (near the Dens), forgiving strategies survive.\")\n",
    "print(f\"Grim trigger collapses under noise. Generous tit-for-tat thrives.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate: grim_trigger vs generous_tit_for_tat with noise\n",
    "def play_match_with_noise(sa_fn, sb_fn, rounds=10, noise=0.05):\n",
    "    \"\"\"Play a match with random action flips (Dens interference).\"\"\"\n",
    "    history_a, history_b = [], []\n",
    "    results = []\n",
    "    for r in range(1, rounds + 1):\n",
    "        action_a = sa_fn(history_a, history_b, r)\n",
    "        action_b = sb_fn(history_b, history_a, r)\n",
    "        if np.random.random() < noise:\n",
    "            action_a = 'defect' if action_a == 'cooperate' else 'cooperate'\n",
    "        if np.random.random() < noise:\n",
    "            action_b = 'defect' if action_b == 'cooperate' else 'cooperate'\n",
    "        pa, pb = PAYOFF_MATRIX[(action_a, action_b)]\n",
    "        history_a.append(action_a)\n",
    "        history_b.append(action_b)\n",
    "        cum_a = sum(rr['payoff_a'] for rr in results) + pa\n",
    "        cum_b = sum(rr['payoff_b'] for rr in results) + pb\n",
    "        results.append({'round': r, 'action_a': action_a, 'action_b': action_b,\n",
    "                        'payoff_a': pa, 'payoff_b': pb,\n",
    "                        'cumulative_a': cum_a, 'cumulative_b': cum_b})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 100 runs with 5% noise\n",
    "grim_scores, generous_scores = [], []\n",
    "for _ in range(100):\n",
    "    m = play_match_with_noise(STRATEGIES['grim_trigger'], STRATEGIES['grim_trigger'], noise=0.05)\n",
    "    grim_scores.append(m.iloc[-1]['cumulative_a'])\n",
    "    m = play_match_with_noise(STRATEGIES['generous_tit_for_tat'], STRATEGIES['generous_tit_for_tat'], noise=0.05)\n",
    "    generous_scores.append(m.iloc[-1]['cumulative_a'])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.hist(grim_scores, bins=15, color='firebrick', alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(np.mean(grim_scores), color='black', linestyle='--')\n",
    "ax1.set_title(f'Grim Trigger vs Grim Trigger (5% noise)\\navg={np.mean(grim_scores):.1f}')\n",
    "ax1.set_xlabel('Cumulative Payoff')\n",
    "\n",
    "ax2.hist(generous_scores, bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(np.mean(generous_scores), color='black', linestyle='--')\n",
    "ax2.set_title(f'Generous TFT vs Generous TFT (5% noise)\\navg={np.mean(generous_scores):.1f}')\n",
    "ax2.set_xlabel('Cumulative Payoff')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Noise devastates grim_trigger but barely affects generous_tit_for_tat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auster's Takeaway: The Requirements for Cooperation\n",
    "\n",
    "Game theory tells Auster exactly what conditions sustain cooperation:\n",
    "\n",
    "1. **Repeated interaction** — one-shot games incentivize defection; repeated games allow reputation\n",
    "2. **Memory** — players must remember past interactions (tit-for-tat needs history)\n",
    "3. **Sufficiently long shadow of the future** — discount factor δ ≥ (T-R)/(T-P)\n",
    "4. **Noise tolerance** — forgiving strategies survive in imperfect environments\n",
    "\n",
    "The blockchain implication: **staking creates all four conditions.** Locked tokens ensure long-term engagement (repetition). On-chain history provides memory. Long lockup periods create a shadow of the future. Slashing with appeal mechanisms provides noise tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: The Population Ecology\n",
    "\n",
    "In Axelrod's tournament, strategies that do well attract followers. Simulate 5 generations where the worst-performing strategy is eliminated each generation. Which strategy is the last one standing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population ecology simulation\n",
    "np.random.seed(867)\n",
    "alive = list(STRATEGIES.keys())\n",
    "\n",
    "print(\"Population ecology (eliminate worst each generation):\\n\")\n",
    "for gen in range(1, 6):\n",
    "    if len(alive) <= 1:\n",
    "        break\n",
    "    scores = {}\n",
    "    for sa in alive:\n",
    "        total = 0\n",
    "        for sb in alive:\n",
    "            m = play_match(STRATEGIES[sa], STRATEGIES[sb])\n",
    "            total += m.iloc[-1]['cumulative_a']\n",
    "        scores[sa] = total / len(alive)\n",
    "    \n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1])\n",
    "    eliminated = sorted_scores[0][0]\n",
    "    alive.remove(eliminated)\n",
    "    \n",
    "    print(f\"Generation {gen}: eliminated {eliminated} (avg={sorted_scores[0][1]:.1f})\")\n",
    "    for s, sc in sorted(scores.items(), key=lambda x: -x[1]):\n",
    "        marker = ' ← ELIMINATED' if s == eliminated else ''\n",
    "        print(f\"    {s:30s} {sc:6.1f}{marker}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Last strategies standing: {alive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Custom Strategy\n",
    "\n",
    "Design a strategy that beats tit-for-tat in a noisy environment. Test it against all 8 strategies with 5% noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_strategy(my_history, opp_history, round_num):\n",
    "    \"\"\"Your custom strategy: cooperate first, forgive one defection, retaliate on two.\"\"\"\n",
    "    if round_num <= 2:\n",
    "        return 'cooperate'\n",
    "    # Look at last 2 opponent moves\n",
    "    if opp_history[-1] == 'defect' and opp_history[-2] == 'defect':\n",
    "        return 'defect'  # Two defections in a row → retaliate\n",
    "    return 'cooperate'  # Otherwise forgive\n",
    "\n",
    "# Test against all strategies with noise\n",
    "np.random.seed(42)\n",
    "custom_scores = {}\n",
    "for name, fn in STRATEGIES.items():\n",
    "    payoffs = []\n",
    "    for _ in range(50):  # 50 runs for statistical significance\n",
    "        m = play_match_with_noise(custom_strategy, fn, noise=0.05)\n",
    "        payoffs.append(m.iloc[-1]['cumulative_a'])\n",
    "    custom_scores[name] = np.mean(payoffs)\n",
    "\n",
    "print(\"Custom strategy vs all opponents (5% noise, 50 runs each):\")\n",
    "for opp, score in sorted(custom_scores.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  vs {opp:30s} avg payoff: {score:.1f}\")\n",
    "print(f\"\\nOverall average: {np.mean(list(custom_scores.values())):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: The Discount Factor Experiment\n",
    "\n",
    "Plot how the tournament rankings change as the discount factor (game length) varies from 2 rounds to 50 rounds. At what game length does tit-for-tat overtake always-defect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tournament rankings by game length\n",
    "np.random.seed(42)\n",
    "lengths = [2, 5, 10, 20, 50]\n",
    "length_rankings = {s: [] for s in STRATEGIES}\n",
    "\n",
    "for n_rounds in lengths:\n",
    "    scores = {}\n",
    "    for sa_name, sa_fn in STRATEGIES.items():\n",
    "        total = 0\n",
    "        for sb_name, sb_fn in STRATEGIES.items():\n",
    "            m = play_match(sa_fn, sb_fn, rounds=n_rounds)\n",
    "            total += m.iloc[-1]['cumulative_a']\n",
    "        scores[sa_name] = total / len(STRATEGIES)\n",
    "    for s, sc in scores.items():\n",
    "        length_rankings[s].append(sc)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for strategy, scores in length_rankings.items():\n",
    "    style = '-' if 'tit' in strategy or 'pavlov' in strategy else '--'\n",
    "    plt.plot(lengths, scores, f'o{style}', label=strategy, linewidth=1.5)\n",
    "plt.xlabel('Game Length (rounds)')\n",
    "plt.ylabel('Average Tournament Score')\n",
    "plt.title('How Game Length Changes Strategy Rankings')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned:\n",
    "\n",
    "1. **Nash equilibrium** — the only stable strategy in one-shot PD is mutual defection\n",
    "2. **Dominant strategies** — defection dominates regardless of what the opponent does\n",
    "3. **Repeated games change everything** — tit-for-tat and cooperative strategies outperform defection when games have history\n",
    "4. **The Folk Theorem** — cooperation is self-enforcing when δ ≥ (T-R)/(T-P)\n",
    "5. **Noise favors forgiveness** — in imperfect environments (near the Dens), generous strategies outperform strict ones\n",
    "\n",
    "**Key insight:** Game theory tells us *when* cooperation can be sustained (repeated games, long time horizons, noise tolerance). Mechanism design — the subject of Tutorial 03 — tells us *how to engineer the rules* so that cooperation is inevitable.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Tutorial:** Mechanism Design — reverse game theory: design the game to get the outcome you want.\n",
    "\n",
    "---\n",
    "\n",
    "> *\"Game theory describes the prison. Mechanism design builds the door.\"*\n",
    ">\n",
    "> — Brenn Auster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
